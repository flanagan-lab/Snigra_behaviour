---
title: "Chasing behaviour analysis"
output: 
  bookdown::pdf_document2:
    fig_caption: yes
    number_sections: no
    toc: yes
editor_options: 
  chunk_output_type: console
header-includes: |
  \usepackage{lipsum} \usepackage{float} \floatplacement{figure}{H}
---

```{r knitsetup, include=FALSE}
knitr::opts_knit$set(root.dir='../',fig_path="../figs/")
```


```{r chunksetup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,out.extra='',fig.pos="H",
                      fig.path = "../figs/",
                      dpi = 300,fig.keep='none',dev='png')
```

```{r loadLibs, message=FALSE}
library(stringr)
library(dplyr)
library(scales)
library(tidyverse)
require(lme4)
library(knitr)
library(VGAM)
```

```{r}
time_cols<-c(AM="#fc8d62",Noon="#e78ac3")
trial_pch<-c(0:7,9:10)
```
```{r}
logit_transform<-function(x){
  xl<-log(x/(1-x))
  return(xl)
}
```

 
This document is for the analysis of the *Stigmatopora nigra* chasing behaviours. During the mesocosm experiments, we noticed that male pipefish frequently 'chased' or followed a single female pipefish, interspersed with courting. 

Following an initial analysis of the courtship behaviours, Fleur van Eyndhoven re-analysed the videos to record chasing. Specifically, for each bout of courtship (which had been previously analysed), she recorded whether the bout ended in chasing, contained any chasing, and the size of the group (number of males and females). 

All of the raw chasing data is found in Chase_datasheets/. 


```{r readSavedData}
chase_data<-read.csv("processed_data/chase_data.csv")

court_data<-read.csv("processed_data/courtship_data.csv")

behav_data<-read.csv("processed_data/combined_behavioural_data.csv")
```



## Analysis of chasing behaviours

Based on our time spent with the fish, we have a few questions we want to address:

* Was chasing more likely to occur in trials with larger females (and/or with larger differences in body size between smallest and largest females)? [this is a trial-level comparison]
* Is chasing more likely when there is a large number of individuals courting? [this is a courtship bout-level comparison]
* Are longer courtship bouts more likely to end in chasing and/or contain chasing? [this is a courtship bout-level comparison]

### Exploratory analysis


First I need to convert the data from a per-observation basis to a per-bout basis. What I need for the analysis are the bout number, the information in `total_time_of_courtship`, the group size, chasing info, the trial number, and the time of day. 

```{r createBoutData}
bout_data<-do.call(rbind,as.list(by(
  data=behav_data,
  INDICES=behav_data$bout_number,
  function(dat){
    bout_dat<- dat[,c("bout_number","Trial", "Time_of_Day","Group_size", "total_time_of_courtship","Chasing_present","Chasing_numeric","Chasing_end","Chasing_end_numeric")]
    bout_dat<-unique(bout_dat)
    bout_dat$Group_size<-mean(bout_dat$Group_size)
    return(unique(bout_dat))
  }
  
)))

bout_data$logDuration<-log(bout_data$total_time_of_courtship)
bout_data$Time_of_Day <- factor(bout_data$Time_of_Day,
                                levels=c("AM","Noon"))
bout_data$Trial <- factor(bout_data$Trial,
                          levels=c(
  "Trial 1",
  "Trial 2",
  "Trial 3",
  "Trial 4",
  "Trial 5",
  "Trial 6",
  "Trial 7",
  "Trial 8",
  "Trial 9",
  "Trial 10"
))
```


Then I'll visualize the data for the two main effects of interest (group size and bout duration) to evaluate if transformation is needed or helpful. It looks like transforming the bout duration will be helpful (Fig. \@ref(fig:yvalsHist))

```{r yvalsHist, fig.cap="Distributions of the variables for group size and bout duration before (top row) and after (bottom row) log-transformation."}
par(mfrow=c(2,2))
hist(bout_data$Group_size, 
     main="",
     xlab="Group size",
     ylab="Number of bouts"
     )
hist(bout_data$total_time_of_courtship,
     main="",
     xlab="Duration (s)",
     ylab="Number of bouts")

hist(log(bout_data$Group_size),
     main="",
     xlab="log(Group size)",
     ylab="Number of bouts")
hist(log(bout_data$total_time_of_courtship),
     main="",
     xlab="log(Duration)",
     ylab="Number of bouts")
```

Another interesting component is to evaluate if a bout contained chasing, how frequently did it end with chasing? We can see most bouts did not contain chasing, and a large number of those that did contain chasing did not end in chasing (Fig. \@ref(fig:chasingPresentEnd)). To some extent, this result is tautological, in that bouts that did not contain chasing had no way of ending in chasing.

```{r chasingPresentEnd, fig.cap="The occurrence of bouts ending in chasing, given that they contained chasing.", fig.height=5, fig.width=5}
plot(table(chase_data$Chasing_present, chase_data$Chasing_end),
     main="")
mtext("The bout ended in chasing",2)
mtext("The bout contained chasing",3)
```
```{r}
kable(table(bout_data$Chasing_present)/nrow(bout_data)*100,"latex",booktab=TRUE)
```

Of the bouts with chasing, how many had chasing as the final behaviour?

```{r}
table(bout_data$Chasing_end[bout_data$Chasing_present=="Yes"])/sum(table(bout_data$Chasing_end[bout_data$Chasing_present=="Yes"]))*100
```


Before fitting models, we also want to check if:
- the variances of data (transformed by the link function) are homogeneous across categories
- the responses of transformed data linear with respect to continuous predictors? 
- outlier individuals or groups exist
- whether distributions within groups match the assumed distribution


```{r variancesPlot, fig.height=7, fig.width=7, fig.cap="Distributions of the response variable (chasing present/absent) as a function of the two predictors and two random effects.", eval=FALSE, include=FALSE}
par(mfrow=c(2,2))
plot(bout_data$Chasing_numeric~bout_data$Group_size)
plot(bout_data$Chasing_numeric~bout_data$logDuration)
plot(bout_data$Chasing_numeric~bout_data$Time_of_Day)
plot(bout_data$Chasing_numeric~bout_data$Trial)
```

```{r variancesPlotFlipped, fig.height=7, fig.width=7, fig.cap="Distributions of the predictor variables as a function of the binomial response variable, chasing present/absent."}
par(mfrow=c(2,2))
plot(bout_data$Group_size~bout_data$Chasing_numeric)
plot(bout_data$logDuration~bout_data$Chasing_numeric)
plot(bout_data$Time_of_Day~bout_data$Chasing_numeric)
plot(bout_data$Trial~bout_data$Chasing_numeric)
```

So these boxplots are ok -- logDuration looks good, and the group size is ok except for trials 9 and 10, and time of day is decently consistent. 

```{r predictedsByCats, fig.height=7, fig.width=7, fig.cap="Distributions of our numeric predictor variables as a function of the categorical random effects."}
par(mfrow=c(2,2))
boxplot(bout_data$Group_size~bout_data$Time_of_Day)
boxplot(bout_data$logDuration~bout_data$Time_of_Day)
boxplot(bout_data$Group_size~bout_data$Trial)
boxplot(bout_data$logDuration~bout_data$Trial)
```

And finally let's check to see if there is autocorrelation in the continuous predictors. 

```{r groupAndDur, fig.cap="The relationship between the two continuous predictor variables."}
plot(bout_data$Group_size~bout_data$logDuration)
```

These plots suggest that I'm probably ok to move forward with these data, but I might consider dropping the observations from Trial 10 and seeing if the model output is different.

### Chasing, group size, bout duration

We can analyse the chasing behaviours within each bout as a function of the overall group size and bout duration, with time of day as a predictor variable and the trial as a random effect.

```{r logitBackTransformFXN}
logit_back<-function(y) { return(exp(y)/(1+exp(y))) }

```
```{r}
source("R_scripts/predicted_probs.R")
```

```{r ChasingMod}
ChaseMod<- glmer(Chasing_numeric~Group_size*logDuration+ (1|Time_of_Day) +(1|Trial), 
                    family="binomial",
                    data=bout_data)
ChaseModSum<-summary(ChaseMod)
ChaseModANOVA<-anova(ChaseMod)

ChaseModSum
```


```{r ChasingModEst}
# get standard errors
ChaseMod_SE <- sqrt(diag(vcov(ChaseMod)))

# convert to prob space
ChaseMod_Est<-cbind(Est = logit_back(fixef(ChaseMod)), 
              LL = logit_back(fixef(ChaseMod) - 1.96 * ChaseMod_SE ), 
              UL = logit_back(fixef(ChaseMod) + 1.96 *ChaseMod_SE ),
              ChaseModSum$coefficients[,3:4])


kable(ChaseMod_Est,"latex",booktab=TRUE)
```

All of the fixed effects in the model were significant (Table \@ref(tab:ChasingMod)), with group size, bout duration, and time of day increasing the probability of chasing occurring (once the variance associated with the trial was partitioned out).

I then created predicted probabilities based on the model to summarize the overall effect. 

```{r ChaseModPredict}
tmpdat <- bout_data[, c("Group_size","logDuration", "Time_of_Day", "Trial")]

# Group size
jvalues <- seq(from = min(bout_data$Group_size), to = max(bout_data$Group_size),length.out=100)
grpChaseMod_predict<-predicted_probs(ChaseMod, tmpdat, "Group_size",jvalues)

# duration (log-transformed)
jvalues <- seq(from = min(bout_data$logDuration), to = max(bout_data$logDuration),length.out=100)
durChaseMod_predict<-predicted_probs(ChaseMod, tmpdat, "logDuration",jvalues)

```

#### Checking assumptions

Let's also check some of the model assumptions and evaluate model fit. The generic model plot, with residuals vs fitted, won't actually tell us that much.

For inspiration on checking assumptions, I drew on the resources in [The Analysis Factor](https://www.theanalysisfactor.com/regression-diagnostics-glmm/) and [Statistical tools for high-throughput analysis](http://www.sthda.com/english/articles/36-classification-methods-essentials/148-logistic-regression-assumptions-and-diagnostics-in-r/).


**Appropriate estimation of variance**

Based on Table \@ref(tab:ChasingMod), we can see that the parameter estimates have a reasonable amount of variation around them, which is a good indicator that the estimation of variance is appropriate. 

**the chosen link function is appropriate**

To evaluate this, we can compare predicted values to actual outcomes -- but we'll need to round/subset/group the data to compare across continuous values.

```{r grpsizeLink, fig.cap="Predicted probabilities as a function of the average observed outcomes, averaged across different group sizes."}
grpSizes<-data.frame(
  avgChasing=unlist(as.list(by(bout_data,bout_data$Group_size, function(dat){
    return(mean(dat$Chasing_numeric))
  })))
)
grpSizes$grpSize <- rownames(grpSizes)

preds<-grpChaseMod_predict[round(grpChaseMod_predict$Variable,1) %in% grpSizes$grpSize,]
preds$Variable<-round(preds$Variable,1)

grpSizes<-merge(grpSizes, preds, by.x = "grpSize",by.y="Variable",all=TRUE)

plot(grpSizes$PredictedProbability~grpSizes$avgChasing)
```

There is a lot of variation with respect to group size in predicted probabilities when no chasing occurred (Fig. \@ref(fig: grpsizeLink)), but the non-zero probabilities appear fairly well correlated. The same appears to be true for bout duration (Fig. \@ref(fig: durationLink)). 

```{r durationLink, fig.cap="Predicted probabilities as a function of the average observed outcomes, averaged across different bout durations."}
durCats<-seq(floor(min(bout_data$logDuration)),ceiling(max(bout_data$logDuration)),by=0.5)

boutDur<-data.frame(matrix(NA, nrow=length(durCats)-1,ncol=3))
colnames(boutDur)<-c("avgChasing","avgDur","predDur")
for(i in 1:length(durCats) - 1){
  boutDur[i,]<-data.frame(
    avgChasing=mean(bout_data$Chasing_numeric[bout_data$logDuration >= durCats[i] & 
                                                bout_data$logDuration < durCats[i+1]]),
    avgDur = mean(durCats[i], durCats[i+1]),
    predDur = mean(durChaseMod_predict$PredictedProbability[durChaseMod_predict$Variable >= durCats[i] &
                                                              durChaseMod_predict$Variable < durCats[i+1]])
  )
}


plot(boutDur$predDur~boutDur$avgChasing)
```

**Random effects come from a normal distribution**

```{r randomeffects, fig.cap="Distribution of random effects from the chasing model."}
rands<-ranef(ChaseMod)

hist(c(rands$Trial[,1],rands$Time_of_Day[,1]), main="",xlab="Random effects")
```

This is not amazingly normal, but I think it's good enough, given that we have so few random effects estimates. 


**linearity of continuous predictor variables and logit of the outcome**

To evaluate this assumption, we need the predicted probabilities and the two continuous variables, group size and the log of bout duration.

```{r chasemodProbs, fig.width=7, fig.cap="The predictor variables as a function of the logit-gransformed predicted probabilities from the chasing model."}
probabilities <- predict(ChaseMod, type="response")
pred_classes<-ifelse(probabilities > 0.5, "yes", "no")

predictors<-c("logDuration","Group_size","Time_of_Day","Trial")

mydata<-cbind(bout_data[,predictors], 
              logit=logit_transform(probabilities))

par(mfrow=c(1,2))
plot(mydata$logDuration~mydata$logit)
plot(mydata$Group_size~mydata$logit)


```

These look ok to me -- roughly linear.

**the variances of data (transformed by the link function) are homogeneous across categories**

This is similar -- we plot the predicted values across each of the categories and ensure similar variances.

```{r variancePlots, fig.width=7, fig.cap="Distributions of the logit-transformed predicted probabilities across the categorical random effects, plotted to inspect variances."}
par(mfrow=c(1,2))
boxplot(mydata$logit~mydata$Trial)
boxplot(mydata$logit~mydata$Time_of_Day)
```

These also look ok, except maybe trial 10. And I think that the distributions within groups match the assumed distributions. 

**No major outliers are present**

We can look at the distribution of residuals and see that they are reasonably normal (Fig. \@ref(fig:histResid)) -- on top of that, it is not highly skewed, with no obvious outliers. So I think we're probably good to proceed with interpreting this analysis!

```{r histResid, fig.cap="Distribution of residuals from the chasing model."}
hist(resid(ChaseMod), main="",xlab="Residuals")
```

We can re-fit the model, but without those potential outliers:

```{r chaseModNoOut}
bout_data_noOut<-bout_data[bout_data$Trial != "Trial 10",]
bout_data_noOut<-bout_data[bout_data_noOut$Group_size <=5,]
ChaseMod_noOut<- glmer(Chasing_numeric~Group_size*logDuration+ (1|Time_of_Day) +(1|Trial), 
                    family="binomial",
                    data=bout_data_noOut)
ChaseMod_noOutSum<-summary(ChaseMod_noOut)
ChaseMod_noOutANOVA<-anova(ChaseMod_noOut)
```


```{r chaseModNoOutEst}
# get standard errors
ChaseMod_noOut_SE <- sqrt(diag(vcov(ChaseMod_noOut)))

# convert to prob space
ChaseMod_noOut_Est<-cbind(Est = logit_back(fixef(ChaseMod_noOut)), 
              LL = logit_back(fixef(ChaseMod_noOut) - 1.96 * ChaseMod_noOut_SE ), 
              UL = logit_back(fixef(ChaseMod_noOut) + 1.96 *ChaseMod_noOut_SE ),
              ChaseMod_noOutSum$coefficients[,3:4])


kable(ChaseMod_noOut_Est,"latex",booktab=TRUE)
```

These estimates are almost identical to the previous ones.

```{r ChaseModPredictNoOut}
tmpdat <- bout_data[, c("Group_size","logDuration", "Time_of_Day", "Trial")]

# Group size
jvalues <- seq(from = min(bout_data$Group_size), to = max(bout_data$Group_size),length.out=100)
grpChaseMod_predict_noOut<-predicted_probs(ChaseMod_noOut, tmpdat, "Group_size",jvalues)

# duration (log-transformed)
jvalues <- seq(from = min(bout_data$logDuration), to = max(bout_data$logDuration),length.out=100)
durChaseMod_predict_noOut<-predicted_probs(ChaseMod_noOut, tmpdat, "logDuration",jvalues)

```

We can also check the assumptions by plotting the fitted lines on top of each other -- they should be basically the same. 

```{r}
par(mfrow=c(1,2))
# group size
plot(jitter(bout_data$Chasing_numeric, 0.25)~bout_data$Group_size,
       pch=trial_pch[bout_data$Trial],
     col=alpha(time_cols[bout_data$Time_of_Day],0.5),
     cex=1.5,
     xlab="Mean Group size",
     ylab="Chasing present",
     yaxt='n',
     bty='l')
axis(2,at=c(0,1),labels=c("No","Yes"),las=1)

# add the predicted probabilities for all data
polygon(c(rev(grpChaseMod_predict$Variable),grpChaseMod_predict$Variable), 
        c(rev(grpChaseMod_predict$Lower),grpChaseMod_predict$Upper),
     col = alpha("grey90",0.5), border = NA)

lines(grpChaseMod_predict$Variable, 
      grpChaseMod_predict$PredictedProbability, lwd = 2)

# add predicted probs for no outlier data
polygon(c(rev(grpChaseMod_predict_noOut$Variable),grpChaseMod_predict_noOut$Variable), 
        c(rev(grpChaseMod_predict_noOut$Lower),grpChaseMod_predict_noOut$Upper),
     col = alpha("orchid4",0.5), border = NA)

lines(grpChaseMod_predict_noOut$Variable, 
      grpChaseMod_predict_noOut$PredictedProbability, lwd = 2,col="orchid")

# duration
plot(jitter(bout_data$Chasing_numeric)~bout_data$logDuration,
     xlab="log(Courtship bout duration (s))",
     ylab="Chasing present",
     yaxt='n',
     bty='l',
     pch=19,
     col=alpha("dark grey",0.5),
     cex=1.5,
     type='n')
axis(2,at=c(0,1),labels=c("No","Yes"),las=1)


# add the predicted probabilities
polygon(c(rev(durChaseMod_predict$Variable),durChaseMod_predict$Variable), 
        c(rev(durChaseMod_predict$Lower),durChaseMod_predict$Upper),
     col = alpha("grey90",0.5), border = NA)

lines(durChaseMod_predict$Variable, 
      durChaseMod_predict$PredictedProbability, lwd = 2)

# add the points
points(jitter(bout_data$Chasing_numeric, 0.5)~bout_data$logDuration,
       pch=trial_pch[bout_data$Trial],
     col=alpha(time_cols[bout_data$Time_of_Day],0.5),
     cex=1.5)
# add predicted probs for no outlier data
polygon(c(rev(durChaseMod_predict_noOut$Variable),durChaseMod_predict_noOut$Variable), 
        c(rev(durChaseMod_predict_noOut$Lower),durChaseMod_predict_noOut$Upper),
     col = alpha("orchid4",0.5), border = NA)

lines(durChaseMod_predict_noOut$Variable, 
      durChaseMod_predict_noOut$PredictedProbability, lwd = 2,col="orchid")


```

These are nearly identical so I think we're probably good to use all of the data.

### Bouts end in chasing

For this analysis, let's restrict it to those bouts that had some chasing in them. Since bouts without chasing are defined as also not ending in chasing, these are not useful pieces of data for this analysis. 

```{r chaseEndData}
chase_end_data<-bout_data[which(bout_data$Chasing_numeric==1),]
```

For this model, the logit link function did not do a good job modeling the variances and was slightly off in the magnitude of the estimates. So I chose to use a cloglog link instead, which fits fairly well (as seen below in the assumptions checking section). 

```{r EndMod}
EndMod<- glmer(Chasing_end_numeric~Group_size*logDuration+(1|Time_of_Day) +(1|Trial),
               family=binomial("cloglog"),
               data=chase_end_data)
EndModSum<-summary(EndMod)
EndModAnova<-anova(EndMod)
EndModSum
```


```{r EndModEst}
# get standard errors
EndMod_SE <- sqrt(diag(vcov(EndMod)))

# convert to prob space
EndMod_Est<-cbind(Est = clogloglink(fixef(EndMod), inverse=TRUE), 
              LL = clogloglink(fixef(EndMod) - 1.96 * EndMod_SE, inverse=TRUE), 
              UL = clogloglink(fixef(EndMod) + 1.96 *EndMod_SE, inverse=TRUE),
              EndModSum$coefficients[,3:4])


kable(EndMod_Est,"latex", booktab=TRUE,
      caption="Table of estimates, their confidence intervals, and their z-scores and p-values.")
```

In this case, none of the fixed effects in the model were significant (Table \@ref(tab:EndMod)). The probability that a bout would end in chasing, without any of the fixed effects, was `r round(EndMod_Est[1,1]*100,2)`%. 

As before, I created predicted probabilities based on the model to summarize the overall (lack of) effects, which were then useful for plotting (Fig. \@ref(fig:plotChasing)).

```{r grpEndModPredict}
tmpdat <- chase_end_data[, c("Group_size","logDuration", "Time_of_Day", "Trial")]

# group size
jvalues <- seq(from = min(chase_end_data$Group_size), to = max(chase_end_data$Group_size),length.out=100)
grpEndMod_predict<-predicted_probs(EndMod, tmpdat, "Group_size",jvalues)

#duration
jvalues <- seq(from = min(chase_end_data$logDuration), to = max(chase_end_data$logDuration),length.out=100)
durEndMod_predict<-predicted_probs(EndMod, tmpdat, "logDuration",jvalues)

```


#### Checking assumptions

Let's also check some of the model assumptions and evaluate model fit. The generic model plot, with residuals vs fitted, won't actually tell us that much.

I'll follow the same approach as for the model of chasing

**Appropriate estimation of variance**

Based on Table \@ref(tab:EndMod), the lower likelihood is pretty low compared to the estimates and the upper likelihood, but this is partly because the upper limit is clearly truncated at 1.   

**the chosen link function is appropriate**

To evaluate this, we can compare predicted values to actual outcomes -- but we'll need to round/subset/group the data to compare across continuous values.

```{r grpsizeLinkEnd, fig.cap="The predicted probabilities from the model of bouts ending in chasing as a function of the mean observed outcomes, averaged across group sizes."}
grpSizes<-data.frame(
  avgChasing=unlist(as.list(by(chase_end_data,chase_end_data$Group_size, function(dat){
    return(mean(dat$Chasing_end_numeric))
  })))
)
grpSizes$grpSize <- rownames(grpSizes)

preds<-grpEndMod_predict[round(grpEndMod_predict$Variable,1) %in% grpSizes$grpSize,]
preds$Variable<-round(preds$Variable,1)

grpSizes<-merge(grpSizes, preds, by.x = "grpSize",by.y="Variable",all=TRUE)

plot(grpSizes$PredictedProbability~grpSizes$avgChasing)
```

There is a lot of variation with respect to group size in predicted probabilities when chasing occurred (Fig. \@ref(fig: grpsizeLinkEnd)), and there's not a hugely strong correlation. The same appears to be true for bout duration (Fig. \@ref(fig: durationLinkEnd)). 

```{r durationLinkEnd, fig.cap="The predicted probabilities from the model of bouts ending in chasing as a function of the mean observed outcomes, averaged across bout durations."}
durCats<-seq(floor(min(chase_end_data$logDuration)),ceiling(max(chase_end_data$logDuration)),by=0.5)

boutDur<-data.frame(matrix(NA, nrow=length(durCats)-1,ncol=3))
colnames(boutDur)<-c("avgChasing","avgDur","predDur")
for(i in 1:length(durCats) - 1){
  boutDur[i,]<-data.frame(
    avgChasing=mean(chase_end_data$Chasing_end_numeric[chase_end_data$logDuration >= durCats[i] & 
                                                chase_end_data$logDuration < durCats[i+1]]),
    avgDur = mean(durCats[i], durCats[i+1]),
    predDur = mean(durEndMod_predict$PredictedProbability[durEndMod_predict$Variable >= durCats[i] &
                                                              durEndMod_predict$Variable < durCats[i+1]])
  )
}


plot(boutDur$predDur~boutDur$avgChasing)
```

These plots do not look ideal, but part of this might be the fact that I'm grouping/comparing by categories of the predictor variables, which appear to have no effect on the response variable. So let's just compare overall means:

```{r sem}
sem<-function(x) { return(sd(x)/sqrt(length(x)))}
```

```{r meanComps}
meanTab<-data.frame(
  Data=c("Actual observations",
         "Predicteds across group size",
         "Predicteds across log bout duration"),
  Mean=c(mean(chase_end_data$Chasing_end_numeric),
         mean(grpEndMod_predict$PredictedProbability),
         mean(durEndMod_predict$PredictedProbability)),
  SEM=c(sem(chase_end_data$Chasing_end_numeric),
         sem(grpEndMod_predict$PredictedProbability),
         sem(durEndMod_predict$PredictedProbability))
         
)

kable(meanTab,"latex",booktab=TRUE, caption="The means of the actual observations and the predicted probabilities for various group sizes and durations.")
```

This suggests that the predicted values are probably in the correct range. 

**Random effects come from a normal distribution**

```{r randomeffectsEnd, fig.cap="Distribution of random effects from the chasing model."}
rands<-ranef(EndMod)

hist(c(rands$Trial[,1],rands$Time_of_Day[,1]), main="",xlab="Random effects")
```

This is not amazingly normal, but I think it's good enough, given that we have so few random effects estimates. 

**linearity of continuous predictor variables and logit of the outcome**

To evaluate this assumption, we need the predicted probabilities and the two continuous variables, group size and the log of bout duration.

```{r endmodProbs, fig.width=7, fig.cap="The predictor variables as a function of the logit-gransformed predicted probabilities from the chasing model."}
probabilities <- predict(EndMod, type="response")
pred_classes<-ifelse(probabilities > 0.5, "yes", "no")

predictors<-c("logDuration","Group_size","Time_of_Day","Trial")

mydata<-cbind(chase_end_data[,predictors], 
              loglog=clogloglink(probabilities))

par(mfrow=c(1,2))
plot(mydata$logDuration~mydata$loglog)
plot(mydata$Group_size~mydata$loglog)


```

These look ok to me -- roughly linear.

**the variances of data (transformed by the link function) are homogeneous across categories**

This is similar -- we plot the predicted values across each of the categories and ensure similar variances.

```{r variancePlotsEnd, fig.width=7, fig.cap="Distributions of the logit-transformed predicted probabilities across the categorical random effects, plotted to inspect variances."}
par(mfrow=c(1,2))
boxplot(mydata$loglog~mydata$Trial)
boxplot(mydata$loglog~mydata$Time_of_Day)
```

These also look ok. 

**No major outliers are present**

We can look at the distribution of residuals and see that they are reasonably normal (Fig. \@ref(fig:histResid)) -- on top of that, it is not highly skewed, with no obvious outliers. So I think we're probably good to proceed with interpreting this analysis!

```{r histResidEnd, fig.cap="Distribution of residuals from the chasing model."}
hist(resid(EndMod), main="",xlab="Residuals")
```


\pagebreak

### Chasing Plots (final)

```{r plotChasing, fig.height=4, fig.width=7.5, fig.cap="The probability of chasing occurring as a result of group size and duration. The bottom row plots the probability of a bout ending in chasing (given that it contained some chasing behaviour in the first place).", fig.keep='last', dev='pdf'}
par(mfrow=c(1,2), mar=c(4,4,2.5,1))
# group size,
plot(jitter(bout_data$Chasing_numeric, 0.25)~bout_data$Group_size,
       pch=trial_pch[bout_data$Trial],
     col=alpha(time_cols[bout_data$Time_of_Day],0.5),
     cex=1.5,
     xlab="Mean Group size",
     ylab="Chasing present",
     yaxt='n',
     bty='l')
axis(2,at=c(0,1),labels=c("No","Yes"),las=1)

# add the predicted probabilities
polygon(c(rev(grpChaseMod_predict$Variable),grpChaseMod_predict$Variable), 
        c(rev(grpChaseMod_predict$Lower),grpChaseMod_predict$Upper),
     col = alpha("grey90",0.5), border = NA)

lines(grpChaseMod_predict$Variable, 
      grpChaseMod_predict$PredictedProbability, lwd = 2)

legend("topright",
       as.expression(bquote(bold("A"))),
       cex=2,bty='n',xpd=TRUE)

# duration
plot(jitter(bout_data$Chasing_numeric, 0.25)~bout_data$logDuration,
     xlab="log(Courtship bout duration (s))",
     ylab="",
     yaxt='n',
     bty='l',
     pch=19,
     col=alpha("dark grey",0.5),
     cex=1.5,
     type='n')
axis(2,at=c(0,1),labels=c("No","Yes"),las=1)


# add the predicted probabilities
polygon(c(rev(durChaseMod_predict$Variable),durChaseMod_predict$Variable), 
        c(rev(durChaseMod_predict$Lower),durChaseMod_predict$Upper),
     col = alpha("grey90",0.5), border = NA)

lines(durChaseMod_predict$Variable, 
      durChaseMod_predict$PredictedProbability, lwd = 2)

# add the points
points(jitter(bout_data$Chasing_numeric, 0.25)~bout_data$logDuration,
       pch=trial_pch[bout_data$Trial],
     col=alpha(time_cols[bout_data$Time_of_Day],0.5),
     cex=1.5)

legend("topright",
       as.expression(bquote(bold("B"))),
       cex=2,bty='n',xpd=TRUE)

# add a legend to the top
par(fig=c(0, 1, 0, 1), oma=c(0, 0, 0, 0),
              mar=c(0, 0, 0, 0), new=TRUE)

plot(0, 0, type='n', bty='n', xaxt='n', yaxt='n')
legend("top",
       c(levels(bout_data$Trial),
         levels(bout_data$Time_of_Day)),
       pch=c(trial_pch, 19,19),
       col=c(rep("black",10),time_cols),
       bty='n',
       ncol=6)



```



### Chasing and female size


```{r propChasingTrial}
# Calculating the proportion of chasing
prop_chasing <- table(chase_data$Trial, chase_data$Chasing_present )
prop_chasing <- as.data.frame(rbind(prop_chasing))
prop_chasing$No <- as.numeric(prop_chasing$No)
prop_chasing$Yes <- as.numeric(prop_chasing$Yes)
prop_chasing$sum <-prop_chasing$No + prop_chasing$Yes
prop_chasing$Prop_No <- round(prop_chasing$No/prop_chasing$sum, 3)
prop_chasing$Prop_Yes <- round(prop_chasing$Yes/prop_chasing$sum, 3)
prop_chasing$Trial <- rownames(prop_chasing)


prop_chase  <- merge(prop_chasing[,c(3:6)], 
                    unique(chase_data[,c("Trial", "Difference", "Max_length")]), 
                    by="Trial")

```

```{r plotLengthDistrs, fig.cap="The relationship between the difference in female lengths and the maximum female length per trial."}
plot(prop_chase$Difference~prop_chase$Max_length,
     cex=1.5,     
     pch=19,
     xlab="Maximum female length (mm)",
     ylab="Difference in female lengths (mm)",
     bty='l',
     ylim=c(15,40),
     xlim=c(110,125))
```

Given that it seems that the maximum length and the difference in female sizes appear to be highly correlated (which makes some amount of sense; Fig. \@ref(fig:plotLengthDistrs)), we should only focus on one. Because Fleur collected some preliminary data suggesting that the relative size of prospective mates, not simply the raw size, is important in informing male decisions, we focused on the difference in body size. 

The best approach to analysing proportion data is to use a beta regression or a Dirchilet distribution ([Douma & Weedman 2019](https://doi.org/10.1111/2041-210X.13234)), but because these are trial-level estimates we don't really have enough data for an analysis of that sort (we have $N$=10). 

```{r propCor, warning=FALSE}
prop_cor<-cor.test(prop_chase$Prop_Yes, prop_chase$Difference,method = "spearman")
prop_cor
```


```{r plotPropChasingBodySize, fig.height=5, fig.width=5, fig.cap="The proportion of time spent chasing in a trial given the maximum difference in female lengths. The points are scaled by the number of bouts in that trial. While a positive trend is apparent from the plot, the correlation is not significant for this sample size of 10 trials.", fig.keep='last'}
plot(prop_chase$Prop_Yes~prop_chase$Difference,
     cex=log(prop_chase$sum)/2,
     pch=19,
     xlab="Difference in female lengths (mm)",
     ylab="Proportion of time spent chasing",
     bty='l',
     ylim=c(0,1),
     xlim=c(15,40))
legend("topleft",
       bty='n',
       legend=c(bquote("Spearman's"~rho==.(round(prop_cor$estimate,3))),
                bquote("                   p"==.(round(prop_cor$p.value,3)))
                ),
       cex=1.5)
```

